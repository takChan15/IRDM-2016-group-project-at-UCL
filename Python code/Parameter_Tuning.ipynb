{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "# This script allows the search of the best hyperparameters of our models\n",
    "# Read the instructions in each cell to use it\n",
    "# Many ideas for this script were based on SciKit tutorial on how to do hyper parameter tuning. Below are the links\n",
    "#   http://scikit-learn.org/stable/modules/grid_search.html\n",
    "#   http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "#   http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import svm\n",
    "\n",
    "# A function to do some data preprocessing\n",
    "def transformDf(a_df):\n",
    "    a_df.loc[:, \"norm_myTfIdf_all\"] = df.loc[:, \"myTfIdf_all\"] / df.loc[:, \"sizeOfQuery\"]\n",
    "    a_df.loc[:, \"norm_myTfIdf_title\"] = df.loc[:, \"myTfIdf_title\"] / df.loc[:, \"sizeOfQuery\"]\n",
    "    a_df.loc[:, \"norm_myTfIdf_desc\"] = df.loc[:, \"myTfIdf_desc\"] / df.loc[:, \"sizeOfQuery\"]\n",
    "    a_df.loc[:, \"norm_myTfIdf_attrib\"] = df.loc[:, \"myTfIdf_attrib\"] / df.loc[:, \"sizeOfQuery\"]\n",
    "\n",
    "    brandMatches_df = pd.get_dummies(df.loc[:, \"brandMatches\"])\n",
    "    brandMatches_df.columns = [\"query_product_brands_noMatch\", \"query_has_no_brand\", \"query_product_brands_match\"]\n",
    "    a_df.loc[:, \"query_product_brands_noMatch\"] = brandMatches_df.loc[:, \"query_product_brands_noMatch\"]\n",
    "    a_df.loc[:, \"query_has_no_brand\"] = brandMatches_df.loc[:, \"query_has_no_brand\"]\n",
    "    a_df.loc[:, \"query_product_brands_match\"] = brandMatches_df.loc[:, \"query_product_brands_match\"]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set this path to your feature file location\n",
    "df = pd.read_csv(\"/Users/taklumbo/Ucl_assignments/IRDM/HomeDepot/featureFiles/train_set/MergedFeatures.csv\", \n",
    "                 delimiter=\",\")\n",
    "\n",
    "transformDf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 204.6min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed: 411.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]RandomizedSearchCV took 25297.26 seconds for 25 candidates parameter settings.[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]\n"
     ]
    }
   ],
   "source": [
    "#This part fine tune parameters for different models. \n",
    "#Set the variable \"modelToSearch\" below to be \n",
    "#RF = Random forest\n",
    "#SVR = Support vector machine with Gaussian kernel\n",
    "#GB = Gradient boosting\n",
    "#EN = Elastic net\n",
    "#LSVR = Linear support vector machine\n",
    "\n",
    "features = ['queryId', 'productId', 'productTitle', 'originalQuery', 'ratioNumberOfQueryTermsIn_title', 'ratioNumberOfExpQueryTermsIn_all', 'productRank_title','ratioNumberOfExpQueryTermsIn_attrib','ratioNumberOfExpQueryTermsIn_desc', 'ratioNumberOfExpQueryTermsIn_title', 'productRank_all', 'sizeOfExpQuery_title', 'ratioNumberOfQueryTermsIn_desc', 'productRank_desc', 'ratioNumberOfQueryTermsIn_all', 'ratioNumberOfQueryTermsIn_attrib', 'productRank_attrib', 'sizeOfQuery', 'sizeOfExpQuery_attrib', 'sizeOfExpQuery_desc', 'sizeOfExpQuery_all', \"norm_myTfIdf_all\", \"norm_myTfIdf_title\", \"norm_myTfIdf_desc\", \"norm_myTfIdf_attrib\", \"norm_myTfIdf_expQuery_all\", \"norm_myTfIdf_expQuery_title\", \"norm_myTfIdf_expQuery_desc\", \"norm_myTfIdf_expQuery_attrib\", \"docLength_all\", \"docLength_title\", \"docLength_desc\", \"docLength_attrib\", \"query_product_brands_noMatch\", \"query_has_no_brand\", \"query_product_brands_match\", \"sim_score_all\", \"sim_rank_all\"]\n",
    "xFeatures = features[4:]\n",
    "\n",
    "y = df.loc[:, 'y'].values\n",
    "X = df.loc[:, xFeatures]\n",
    "\n",
    "steps = None\n",
    "param_dist = None\n",
    "\n",
    "modelToSearch = \"SVR\" #RF, SVR, GB, EN, LSVR\n",
    "\n",
    "if modelToSearch == \"RF\":\n",
    "    steps = [('scaler', StandardScaler()), ('RF', RandomForestRegressor())]\n",
    "    param_dist = {\"RF__max_depth\": [3, None],\n",
    "              \"RF__max_features\": sp_randint(1, X.columns.size),\n",
    "              \"RF__min_samples_split\": sp_randint(1, 11),\n",
    "              \"RF__min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"RF__bootstrap\": [True, False],\n",
    "              \"RF__n_estimators\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "             }\n",
    "    \n",
    "elif modelToSearch == \"GB\":\n",
    "    steps = [('scaler', StandardScaler()), ('GB', GradientBoostingRegressor())]\n",
    "    param_dist = {'GB__learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "                'GB__max_depth': [1, 4, 6],\n",
    "                'GB__min_samples_leaf': [1, 3, 5, 9, 17], \n",
    "                'GB__max_features': [1.0, 0.5, 0.1],\n",
    "                'GB__n_estimators': [100, 300, 500]\n",
    "                  }\n",
    "elif modelToSearch == \"SVR\":\n",
    "    steps = [('scaler', StandardScaler()), ('SVR', svm.SVR(cache_size=500, verbose=True))]\n",
    "    param_dist = {'SVR__C': [math.pow(2, -5), math.pow(2, -3), math.pow(2, -1), 1.0, math.pow(2, 1), math.pow(2, 3)],\n",
    "                'SVR__gamma': [math.pow(2, -5), math.pow(2, -3), math.pow(2, -1), 1.0, math.pow(2, 1), math.pow(2, 3)]\n",
    "                  }\n",
    "elif modelToSearch == \"EN\": #Elastic net\n",
    "    steps = [('scaler', StandardScaler()), ('EN', ElasticNet())]\n",
    "    param_dist = {'EN__l1_ratio': [.1, .5, .7, .9, .95, .99, 1]\n",
    "                  }\n",
    "elif modelToSearch == \"LSVR\":\n",
    "    steps = [('scaler', StandardScaler()), ('LSVR', svm.LinearSVR())]\n",
    "    param_dist = {'LSVR__C': [math.pow(2, -5), math.pow(2, -3), math.pow(2, -1), 1.0, math.pow(2, 1), math.pow(2, 3)]}\n",
    "    \n",
    "    \n",
    "pipeline = Pipeline(steps)\n",
    "    \n",
    "# run randomized search\n",
    "n_iter_search = 25\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, cv=3, verbose=1,\n",
    "                                   n_iter=n_iter_search, scoring=\"mean_squared_error\", n_jobs=-1,\n",
    "                                  error_score=0)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean RMSE: 0.476 (std: 0.013)\n",
      "Parameters: {'SVR__C': 0.5, 'SVR__gamma': 0.03125}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean RMSE: 0.476 (std: 0.014)\n",
      "Parameters: {'SVR__C': 0.125, 'SVR__gamma': 0.03125}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean RMSE: 0.477 (std: 0.015)\n",
      "Parameters: {'SVR__C': 0.125, 'SVR__gamma': 0.125}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After the cross validation is finised, you can run this snipplet of code to get the 3 top parameter sets\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        \n",
    "        mean = math.sqrt(-1 * score.mean_validation_score)\n",
    "        sd = np.std(np.sqrt(-1 * score.cv_validation_scores))\n",
    "        \n",
    "        print(\"Mean RMSE: {0:.3f} (std: {1:.3f})\".format(mean, sd))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "        \n",
    "report(random_search.grid_scores_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
