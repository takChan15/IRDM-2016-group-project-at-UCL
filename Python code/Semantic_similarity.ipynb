{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This script generates the Semantic Similarity score using GenSim tool\n",
    "# Read the comments at each cell to use it\n",
    "# This script is based on the tutorial provided on https://radimrehurek.com/gensim/tutorial.html\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from gensim import corpora, models, similarities\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell contains common functions used to interact with GenSim\n",
    "# You don't have to change anthing here\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "dictionaryKey = \"dictionary\"\n",
    "corpusKey = \"corpus\"\n",
    "tfidfKey = \"tfidf\"\n",
    "lsiKey = \"lsi\"\n",
    "similarityIndexKey = \"sim_index\"\n",
    "id2docNameKey = \"id2docName\"\n",
    "docName2IdKey = \"docName2Id\"\n",
    "\n",
    "# Transform a text to its LSI vector representation\n",
    "def toLsi(text, aDictionary, tfidf_index, lsi_index):\n",
    "    text_bow = aDictionary.doc2bow(text.lower().split())\n",
    "    text_tfidf = tfidf_index[text_bow]\n",
    "    return lsi_index[text_tfidf]\n",
    "\n",
    "def toLsi2(text, indexes_map):\n",
    "    return toLsi(text, indexes_map[dictionaryKey], indexes_map[tfidfKey], indexes_map[lsiKey])\n",
    "\n",
    "# Returns the similarity score\n",
    "def getSimilarity(simResult, docName, docToIdMap):\n",
    "    docId = docToIdMap.get(docName, -1)\n",
    "    if docId == -1:\n",
    "        return 0.0\n",
    "    \n",
    "    for aSim in simResult:\n",
    "        if aSim[0] == docId:\n",
    "            return aSim[1]\n",
    "    return 0.0\n",
    "\n",
    "def getSimilarity2(simResult, docName, indexes_map):\n",
    "    return getSimilarity(simResult, docName, indexes_map[docName2IdKey])\n",
    "\n",
    "#Return the ranking of a document for a query. If not found, returns 0\n",
    "def getRanking(sortedSimResult, docName, docToIdMap):\n",
    "    docId = docToIdMap.get(docName, -1)\n",
    "    if docId == -1:\n",
    "        return 0\n",
    "    \n",
    "    ranking = 1\n",
    "    for aSim in sortedSimResult:\n",
    "        if aSim[0] == docId:\n",
    "            if (ranking > 101):\n",
    "                return 101\n",
    "            else:\n",
    "                return ranking\n",
    "        ranking = ranking + 1\n",
    "    return 0\n",
    "\n",
    "def getRanking2(sortedSimResult, docName, indexes_map):\n",
    "    return getRanking(sortedSimResult, docName, indexes_map[docName2IdKey])\n",
    "\n",
    "def sortSimilarities(similarities):\n",
    "    return sorted(enumerate(similarities), key=lambda item: -item[1])\n",
    "\n",
    "# BUild indexes\n",
    "def buildIndexes(sourceDir):\n",
    "    #rootDir = '/Users/taklumbo/Ucl_assignments/IRDM/HomeDepot/'\n",
    "    #path = rootDir + 'data/lsi_all/'\n",
    "    documents = []\n",
    "    frequency = defaultdict(int)\n",
    "    #id2docName = {}\n",
    "    docName2Id = {}\n",
    "\n",
    "    i = 0\n",
    "    for infile in glob.glob( os.path.join(sourceDir, '*.txt') ):\n",
    "        file = open(infile, 'r')\n",
    "        content = file.read().split()\n",
    "\n",
    "        aDoc = []\n",
    "        for aToken in content:\n",
    "            frequency[aToken] += 1\n",
    "            aDoc.append(aToken)\n",
    "\n",
    "        documents.append(aDoc)\n",
    "\n",
    "        docName = infile.split(\"/\")[-1].split(\".\")[0]\n",
    "        #id2docName[i] = docName\n",
    "        docName2Id[docName] = i\n",
    "\n",
    "        i = i + 1\n",
    "        #if i > 5:\n",
    "         #   break \n",
    "\n",
    "    for aDoc in documents:\n",
    "        uniqueTokensInCorpus = []\n",
    "        for aToken in aDoc:\n",
    "            if frequency[aToken] == 1:\n",
    "                uniqueTokensInCorpus.append(aToken)\n",
    "\n",
    "        [aDoc.remove(uniqueToken) for uniqueToken in uniqueTokensInCorpus]\n",
    "\n",
    "\n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "    corpus = [dictionary.doc2bow(aDoc) for aDoc in documents]\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    lsi = models.LsiModel(corpus_tfidf, id2word=dictionary)\n",
    "    corpus_lsi = lsi[corpus_tfidf]\n",
    "\n",
    "    sim_index = similarities.MatrixSimilarity(corpus_lsi)\n",
    "    \n",
    "    indexes = {dictionaryKey: dictionary, corpusKey: corpus, tfidfKey: tfidf, lsiKey: lsi, \n",
    "               similarityIndexKey: sim_index, docName2IdKey: docName2Id} #, id2docNameKey: id2docName}\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def saveIndexes(indexes, targetDir):\n",
    "    indexes[dictionaryKey].save(targetDir + dictionaryKey + '.ser')\n",
    "    corpora.MmCorpus.serialize(targetDir + corpusKey + '.ser', indexes[corpusKey])\n",
    "    indexes[tfidfKey].save(targetDir + tfidfKey + '.ser')\n",
    "    indexes[lsiKey].save(targetDir + lsiKey + '.ser')\n",
    "    indexes[similarityIndexKey].save(targetDir + similarityIndexKey + '.ser')\n",
    "    pickle.dump(indexes[docName2IdKey], open(targetDir + docName2IdKey + \".ser\", \"wb\"))\n",
    "    \n",
    "def loadIndexes(indexDir):\n",
    "    indexes = {}\n",
    "    indexes[dictionaryKey] = corpora.Dictionary.load(indexDir + dictionaryKey + '.ser')\n",
    "    indexes[corpusKey] = corpora.MmCorpus(indexDir + corpusKey + '.ser')\n",
    "    indexes[tfidfKey] = models.TfidfModel.load(indexDir + tfidfKey + '.ser')\n",
    "    indexes[lsiKey] = models.LsiModel.load(indexDir + lsiKey + '.ser')\n",
    "    indexes[similarityIndexKey] = similarities.MatrixSimilarity.load(indexDir + similarityIndexKey + '.ser')\n",
    "    indexes[docName2IdKey] = pickle.load( open( indexDir + docName2IdKey + '.ser', \"rb\" ) )\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    }
   ],
   "source": [
    "# If you don't have an GenSim index, you can run this cell to build it\n",
    "# Below is the path to HomeDepot product files. These are used to build the indexes\n",
    "\n",
    "myIndexes = buildIndexes(\"/Users/taklumbo/Ucl_assignments/IRDM/HomeDepot/data/lsi_all/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This save the indexes to disk at the location of your choice\n",
    "\n",
    "saveIndexes(myIndexes, \"/Users/taklumbo/Ucl_assignments/IRDM/HomeDepot/lsi_index_all/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This load the indexes from disk. Set the path\n",
    "\n",
    "newIndexes = loadIndexes(\"/Users/taklumbo/Ucl_assignments/IRDM/HomeDepot/lsi_index_all/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set this to the query file provided by HomeDepot. Either train.csv or test.csv\n",
    "\n",
    "queryFile = \"/Users/taklumbo/Ucl_assignments/IRDM/HomeDepot/RawData/lsi_test_all_1.csv\"\n",
    "queryData = pd.read_csv(queryFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the path below to the file in which you want to save the generated similarty scores\n",
    "\n",
    "file = open('/Users/taklumbo/Ucl_assignments/IRDM/HomeDepot/featureFiles/test_set/lsi_all_1.csv', 'w')\n",
    "file.write('queryId,productId,sim_score_all,sim_rank_all\\n')\n",
    "\n",
    "for i in range(0, len(queryData)):\n",
    "    #print(queryData.loc[i, \"search_term\"])\n",
    "    searchTerm = queryData.iloc[i, 3]\n",
    "    queryId = queryData.iloc[i, 0]\n",
    "    productId = queryData.iloc[i, 1]\n",
    "    \n",
    "    #print(searchTerm + \" \" + str(queryId) + \" \" + str(productId))\n",
    "    \n",
    "    searchTermVector = toLsi2(searchTerm, newIndexes)\n",
    "    if (len(searchTermVector) > 0):\n",
    "        result = newIndexes[similarityIndexKey][searchTermVector]\n",
    "        result = sortSimilarities(result)\n",
    "    \n",
    "        simScore = getSimilarity2(result, str(productId), newIndexes)\n",
    "        ranking = getRanking2(result, str(productId), newIndexes)\n",
    "        file.write(str(queryId) + \",\" + str(productId) + \",\" + str(simScore) + \",\" + str(ranking) + \"\\n\")\n",
    "        \n",
    "    else:\n",
    "        file.write(str(queryId) + \",\" + str(productId) + \",-1,101\\n\")\n",
    "    \n",
    "    #if i == 10:\n",
    "     #   break\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0505577\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "# Use for debugging\n",
    "\n",
    "myVec = toLsi2(\"90 degree bracket\", newIndexes)\n",
    "myRes = newIndexes[similarityIndexKey][myVec]\n",
    "\n",
    "theDoc = \"100001\"\n",
    "myRes = sortSimilarities(myRes)\n",
    "print(getSimilarity2(myRes, theDoc, newIndexes))\n",
    "print(getRanking2(myRes, theDoc, newIndexes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
